{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Libraries Performance and GPU Utilization Check\n",
    "\n",
    "This script checks the installation and performance of various machine learning libraries. It assesses both CPU and GPU performance (if available) for each library.\n",
    "\n",
    "## Import Required Libraries\n",
    "\n",
    "We begin by importing necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec  7 08:43:26 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 546.17       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080        On  | 00000000:01:00.0  On |                  N/A |\n",
      "| 30%   40C    P0              41W / 288W |   3292MiB / 16376MiB |      2%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A       451      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A     34453      C   /python3.10                               N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "\n",
    "# Suppressing warnings, especially for TensorFlow\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measurement Functions\n",
    "\n",
    "For each library, we define a function to measure its performance on both CPU and GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Availability Check\n",
    "\n",
    "We also check if the GPU is available for each library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec  7 09:06:09 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 546.17       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080        On  | 00000000:01:00.0  On |                  N/A |\n",
      "| 30%   39C    P0              40W / 288W |  15963MiB / 16376MiB |      2%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A       451      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A     34453      C   /python3.10                               N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "+--------------+------+------------+---------------------+---------+\n",
      "| Library      | Test | CPU Time (ms) | GPU Time (ms)       | Speedup |\n",
      "+--------------+------+------------+---------------------+---------+\n",
      "| torch        | 1    | 8.658171   | 0.2181529998779297  | 39.69x  |\n",
      "| torch        | 2    | 7.759571   | 0.2117156982421875  | 36.65x  |\n",
      "| torch        | 3    | 8.168936   | 0.16951560974121094 | 48.19x  |\n",
      "| torch        | 4    | 7.676840   | 0.23174285888671875 | 33.13x  |\n",
      "| torch        | 5    | 10.199547  | 0.1895427703857422  | 53.81x  |\n",
      "| torch        | 6    | 9.292841   | 0.09441375732421875 | 98.43x  |\n",
      "| torch        | 7    | 10.226488  | 0.10347366333007812 | 98.83x  |\n",
      "| torch        | 8    | 9.066343   | 0.13136863708496094 | 69.01x  |\n",
      "| torch        | 9    | 10.228395  | 0.11706352233886719 | 87.37x  |\n",
      "| torch        | 10   | 9.258270   | 0.11038780212402344 | 83.87x  |\n",
      "| tensorflow   | 1    | 11.418819  | 0.7932186126708984  | 14.40x  |\n",
      "| tensorflow   | 2    | 6.271124   | 0.4742145538330078  | 13.22x  |\n",
      "| tensorflow   | 3    | 6.125927   | 0.4792213439941406  | 12.78x  |\n",
      "| tensorflow   | 4    | 4.942894   | 0.41985511779785156 | 11.77x  |\n",
      "| tensorflow   | 5    | 5.110264   | 0.3848075866699219  | 13.28x  |\n",
      "| tensorflow   | 6    | 4.688978   | 0.41031837463378906 | 11.43x  |\n",
      "| tensorflow   | 7    | 4.455090   | 0.3733634948730469  | 11.93x  |\n",
      "| tensorflow   | 8    | 4.504204   | 0.37598609924316406 | 11.98x  |\n",
      "| tensorflow   | 9    | 5.317211   | 0.4649162292480469  | 11.44x  |\n",
      "| tensorflow   | 10   | 4.755259   | 0.4680156707763672  | 10.16x  |\n",
      "| scikit-learn | 1    | 188.431263 | N/A                 | N/A     |\n",
      "| scikit-learn | 2    | 190.107346 | N/A                 | N/A     |\n",
      "| scikit-learn | 3    | 189.799786 | N/A                 | N/A     |\n",
      "| scikit-learn | 4    | 193.338871 | N/A                 | N/A     |\n",
      "| scikit-learn | 5    | 188.552856 | N/A                 | N/A     |\n",
      "| scikit-learn | 6    | 193.812847 | N/A                 | N/A     |\n",
      "| scikit-learn | 7    | 193.957806 | N/A                 | N/A     |\n",
      "| scikit-learn | 8    | 186.780453 | N/A                 | N/A     |\n",
      "| scikit-learn | 9    | 198.884487 | N/A                 | N/A     |\n",
      "| scikit-learn | 10   | 194.298267 | N/A                 | N/A     |\n",
      "+--------------+------+------------+---------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Nvidia Check\n",
    "!nvidia-smi\n",
    "\n",
    "# Performance Measurement for PyTorch\n",
    "def measure_performance_torch(device, size=1000):\n",
    "    start_time = time.time()\n",
    "    a = torch.rand(size, size, device=device)\n",
    "    b = torch.rand(size, size, device=device)\n",
    "    torch.matmul(a, b)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# Performance Measurement for TensorFlow\n",
    "def measure_performance_tensorflow(device_name, size=1000):\n",
    "    with tf.device(device_name):\n",
    "        start_time = time.time()\n",
    "        a = tf.random.normal([size, size])\n",
    "        b = tf.random.normal([size, size])\n",
    "        tf.matmul(a, b)\n",
    "        end_time = time.time()\n",
    "        return end_time - start_time\n",
    "\n",
    "# Performance Measurement for Scikit-learn\n",
    "def measure_performance_sklearn(size=1000):\n",
    "    X, y = make_classification(n_samples=size, n_features=20, n_classes=2, random_state=42)\n",
    "    clf = RandomForestClassifier()\n",
    "    start_time = time.time()\n",
    "    clf.fit(X, y)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# Check GPU support for libraries\n",
    "def check_gpu_support(library):\n",
    "    if library == 'torch' and torch.cuda.is_available():\n",
    "        return True, torch.cuda.get_device_name(0)\n",
    "    elif library == 'tensorflow' and tf.config.list_physical_devices('GPU'):\n",
    "        return True, None\n",
    "    else:\n",
    "        return False, None\n",
    "\n",
    "# Main function to measure and display performance\n",
    "def main():\n",
    "    libraries_to_test = [\"torch\", \"tensorflow\", \"scikit-learn\"]  # Libraries to test\n",
    "    num_tests = 10  # Number of tests per library\n",
    "    results = []  # Storing results\n",
    "\n",
    "    for lib in libraries_to_test:\n",
    "        gpu_available, gpu_name = check_gpu_support(lib)\n",
    "        for i in range(num_tests):\n",
    "            if lib == 'torch':\n",
    "                cpu_time = measure_performance_torch(\"cpu\")\n",
    "                gpu_time = measure_performance_torch(\"cuda\") if gpu_available else None\n",
    "            elif lib == 'tensorflow':\n",
    "                cpu_time = measure_performance_tensorflow(\"/cpu:0\")\n",
    "                gpu_time = measure_performance_tensorflow(\"/gpu:0\") if gpu_available else None\n",
    "            elif lib == 'scikit-learn':\n",
    "                cpu_time = measure_performance_sklearn()\n",
    "                gpu_time = None\n",
    "            \n",
    "            # Store the results\n",
    "            results.append({\n",
    "                \"Library\": lib,\n",
    "                \"Test\": i + 1,\n",
    "                \"CPU Time (ms)\": cpu_time * 1000,  # Convert to milliseconds\n",
    "                \"GPU Time (ms)\": gpu_time * 1000 if gpu_time else \"N/A\",  # Convert to milliseconds\n",
    "                \"GPU Available\": gpu_available,\n",
    "                \"GPU Name\": gpu_name\n",
    "            })\n",
    "\n",
    "    # Print results in a tabular format\n",
    "    print_table(results)\n",
    "\n",
    "# Function to print results in a table format\n",
    "def print_table(data):\n",
    "    # Determine the maximum width needed for each column\n",
    "    column_widths = {\n",
    "        \"Library\": max(len(row[\"Library\"]) for row in data),\n",
    "        \"Test\": len(\"Test\"),\n",
    "        \"CPU Time (ms)\": max(len(f\"{row['CPU Time (ms)']:.6f}\") for row in data),\n",
    "        \"GPU Time (ms)\": max(len(str(row[\"GPU Time (ms)\"])) for row in data),\n",
    "        \"Speedup\": len(\"Speedup\")\n",
    "    }\n",
    "\n",
    "    # Headers\n",
    "    headers = [\"Library\", \"Test\", \"CPU Time (ms)\", \"GPU Time (ms)\", \"Speedup\"]\n",
    "    header_row = \"| \" + \" | \".join(headers[i].ljust(column_widths[headers[i]]) for i in range(len(headers))) + \" |\"\n",
    "\n",
    "    # Separator\n",
    "    separator = \"+-\" + \"-+-\".join([\"-\" * column_widths[header] for header in headers]) + \"-+\"\n",
    "\n",
    "    # Print the table\n",
    "    print(separator)\n",
    "    print(header_row)\n",
    "    print(separator)\n",
    "    for row in data:\n",
    "        cpu_time = row[\"CPU Time (ms)\"]\n",
    "        gpu_time = row[\"GPU Time (ms)\"]\n",
    "        # Calculate speedup\n",
    "        if gpu_time != \"N/A\" and float(gpu_time) > 0:\n",
    "            speedup = cpu_time / float(gpu_time)\n",
    "            speedup_text = f\"{speedup:.2f}x\" if speedup >= 1 else f\"{100 * (1 - gpu_time / cpu_time):.2f}% faster\"\n",
    "        else:\n",
    "            speedup_text = \"N/A\"\n",
    "\n",
    "        formatted_row = \"| \" + \" | \".join([\n",
    "            row[\"Library\"].ljust(column_widths[\"Library\"]),\n",
    "            str(row[\"Test\"]).ljust(column_widths[\"Test\"]),\n",
    "            f\"{row['CPU Time (ms)']:.6f}\".ljust(column_widths[\"CPU Time (ms)\"]),\n",
    "            str(row[\"GPU Time (ms)\"]).ljust(column_widths[\"GPU Time (ms)\"]),\n",
    "            speedup_text.ljust(column_widths[\"Speedup\"])\n",
    "        ]) + \" |\"\n",
    "        print(formatted_row)\n",
    "    print(separator)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all essential libraries including Cudf to speed up Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDF - GPU Dataframe\n",
    "# cudf is a GPU DataFrame library for loading, joining, aggregating, filtering, and otherwise manipulating tabular data using a DataFrame style API.    \n",
    "  \n",
    "%load_ext cudf.pandas\n",
    "\n",
    "# Importing libraries\n",
    "#=============================\n",
    "import cudf\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import folium\n",
    "#=============================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
